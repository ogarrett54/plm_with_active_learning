{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb38d989",
   "metadata": {},
   "source": [
    "## Approach 3: Bootstrapped Ensemble\n",
    "The first ensemble approach tested whether simply training 5 independent models with randomly initialized weights would enable calculation of a variance for predictions on unlabeled samples maximized. This may have been a weak form of calculating variance. A better approach may be to make the models even more different from each other by bootstrapping - that is, using a random subset (e.g. 90%) of the data to train each model independently, then see what they disagree on. I was particularly encouraged to try this bootstrapped ensemble method when I noticed that the paper [Active learning-assisted directed evolution](https://www.nature.com/articles/s41467-025-55987-8) used this approach for their top performing DNN Ensemble method.\n",
    "\n",
    "This will not improve my hypothesized main issue I discussed last time of ensuring diversity is high in the newly selected samples. I will work on that next time and apply that to this new bootstrapped ensemble along with the dropout method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b35af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.data_utils import train_val_test_split\n",
    "from scripts.config import (\n",
    "    DATA_PATH, \n",
    "    SEQUENCE_COL, \n",
    "    SCORE_COL, \n",
    "    TOK_MODEL, \n",
    "    VAL_SPLIT,\n",
    "    TEST_SPLIT,\n",
    "    BATCH_SIZE,\n",
    "    RANDOM_SEED,\n",
    ")\n",
    "\n",
    "training_pool, val_dataloader, test_dataloader = train_val_test_split(\n",
    "    DATA_PATH,\n",
    "    SEQUENCE_COL,\n",
    "    SCORE_COL,\n",
    "    TOK_MODEL,\n",
    "    VAL_SPLIT,\n",
    "    TEST_SPLIT,\n",
    "    BATCH_SIZE,\n",
    "    RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49571bd0",
   "metadata": {},
   "source": [
    "Compared to approach 1, the main thing that should change is that the train dataloader from acquire_new_batch should be subsetted from immediately before training a new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06aecc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from scripts.training import initialize_and_train_new_model\n",
    "from scripts.acquisition import get_pool_predictions\n",
    "\n",
    "def get_bootstrap_sample(labeled_indices, pool_dataset, train_dataloader_batch_size):\n",
    "    bootstrap_indices = np.random.choice(labeled_indices, size=int(0.9*len(labeled_indices)),replace=True)\n",
    "    bootstrap_subset = Subset(pool_dataset, bootstrap_indices)\n",
    "    bootstrap_dataloader = DataLoader(bootstrap_subset, batch_size=train_dataloader_batch_size, shuffle=True)\n",
    "    return bootstrap_dataloader\n",
    "\n",
    "def train_ensemble(\n",
    "        n_models, \n",
    "        model_name, \n",
    "        approach,\n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        epochs,\n",
    "        labeled_indices,\n",
    "        train_dataloader_batch_size,\n",
    "        pool_dataset, \n",
    "        pool_dataloader, \n",
    "        val_dataloader,\n",
    "        patience\n",
    "        ):\n",
    "    \n",
    "    # define list to store predictions as each model is trained then evaluated\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\nTraining Model {i+1}...\")\n",
    "        # set a changing manual seed\n",
    "        torch.manual_seed(i)\n",
    "        torch.cuda.manual_seed(i)\n",
    "\n",
    "        # get bootstrap sample from labeled dataset\n",
    "        bootstrap_dataloader = get_bootstrap_sample(labeled_indices, pool_dataset, train_dataloader_batch_size)\n",
    "\n",
    "        # initialize and train a new model\n",
    "        model = initialize_and_train_new_model(approach, model_name, learning_rate, weight_decay, epochs, bootstrap_dataloader, val_dataloader, patience)\n",
    "        \n",
    "        # get model predictions on pool dataloader, append to ensemble predictions list\n",
    "        pool_preds = get_pool_predictions(model, pool_dataloader, )\n",
    "        ensemble_predictions.append(pool_preds)\n",
    "\n",
    "    # stack ensemble predictions to create tensor of shape (n_models, n_unlabeled_samples)\n",
    "    ensemble_predictions = torch.stack(ensemble_predictions, dim=0)\n",
    "    print(\"Ensemble training complete, submitting predictions for next cycle.\")\n",
    "    # return list of ensemble predictions\n",
    "    return ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3242f608",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from scripts.acquisition import acquire_new_batch, get_variances\n",
    "from scripts.training import initialize_and_train_new_model, test_model\n",
    "from scripts.campaigns import run_standard_finetuning\n",
    "\n",
    "\n",
    "def get_learning_curves(\n",
    "        n_samples,\n",
    "        initial_n_samples,\n",
    "        n_samples_per_batch,\n",
    "        model_name, \n",
    "        approach,\n",
    "        learning_rate, \n",
    "        weight_decay, \n",
    "        epochs, \n",
    "        training_pool, \n",
    "        train_dataloader_batch_size,\n",
    "        pool_dataloader_batch_size,\n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        patience=5,\n",
    "        n_models=5,\n",
    "        results_path=\"active_vs_standard_learning_curves.csv\"\n",
    "):\n",
    "    results_path = Path(results_path)\n",
    "    results_dir = results_path.parent\n",
    "    results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load existing results if the file exists, otherwise start with a fresh DataFrame.\n",
    "    if results_path.exists():\n",
    "        all_results_df = pd.read_csv(results_path)\n",
    "    else:\n",
    "        all_results_df = pd.DataFrame()\n",
    "    \n",
    "    total_pool_size = len(training_pool)\n",
    "    unlabeled_indices = np.arange(total_pool_size)\n",
    "    labeled_indices = np.array([], dtype=np.int64)\n",
    "\n",
    "    ensemble_predictions = None\n",
    "    current_cycle = 1\n",
    "    total_cycles = int(np.ceil((n_samples-initial_n_samples)/n_samples_per_batch)) + 1\n",
    "    \n",
    "    while len(labeled_indices) < n_samples and len(unlabeled_indices) > 0:\n",
    "        print(f\"\\nCycle {current_cycle}/{total_cycles}\\n-------------------------------------------------\")\n",
    "\n",
    "        # on the first cycle, choose random samples of initial_n_samples size\n",
    "        if ensemble_predictions is None:\n",
    "            print(f\"Choosing initial {initial_n_samples} samples randomly...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, train_dataloader_batch_size, pool_dataloader_batch_size, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=None\n",
    "            )\n",
    "        # each other time, use the n_samples_per_batch with acquisition scores to select\n",
    "        else:\n",
    "            scores = get_variances(ensemble_predictions, f\"results/03_bootstrap_ensemble/variances{current_cycle}.csv\")\n",
    "            print(f\"Selecting new data points...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, train_dataloader_batch_size, pool_dataloader_batch_size, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=scores\n",
    "            )\n",
    "        \n",
    "        # give message when loop ends\n",
    "        if len(unlabeled_indices) == 0:\n",
    "            print(\"Unlabeled pool is empty. Proceeding to final model training.\")\n",
    "            break\n",
    "        \n",
    "        # evaluate active vs standard\n",
    "        final_results = []\n",
    "\n",
    "        # active\n",
    "        print(f\"\\nTraining and evaluating model using {len(labeled_indices)} actively selected samples...\")\n",
    "        model_active = initialize_and_train_new_model(approach, model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history=False)\n",
    "        results_active = test_model(model_active, test_dataloader, return_results=True)\n",
    "        results_active = {\n",
    "            'changing_var': 'n_samples',\n",
    "            'local_exp_idx': current_cycle-1,\n",
    "            'value': len(labeled_indices),\n",
    "            'training_method': 'active',\n",
    "            **results_active\n",
    "        }\n",
    "        final_results.append(results_active)\n",
    "\n",
    "        # standard\n",
    "        print(f\"\\nTraining and evaluating model using {len(labeled_indices)} randomly selected samples...\")\n",
    "        model_standard, _ = run_standard_finetuning(len(labeled_indices), approach, model_name, train_dataloader_batch_size, learning_rate, weight_decay, epochs, training_pool, val_dataloader, patience)\n",
    "        results_standard = test_model(model_standard, test_dataloader, return_results=True)\n",
    "        results_standard = {\n",
    "            'changing_var': 'n_samples',\n",
    "            'local_exp_idx': current_cycle-1,\n",
    "            'value': len(labeled_indices),\n",
    "            'training_method': 'standard',\n",
    "            **results_standard\n",
    "        }\n",
    "        final_results.append(results_standard)\n",
    "        # save to disk each time to save progress\n",
    "        results_df = pd.DataFrame(final_results)\n",
    "        all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)\n",
    "        all_results_df.to_csv(results_path, index=False)\n",
    "        print(f\"Progress for experiment {current_cycle-1} appended to {results_path}\")\n",
    "\n",
    "        # if it's the last cycle, skip ensemble predictions\n",
    "        if (current_cycle == total_cycles):\n",
    "            print(\"Experiments complete.\")\n",
    "            break\n",
    "\n",
    "        print(\"Starting ensemble training and pool evaluation...\")\n",
    "        ensemble_predictions = train_ensemble(n_models, model_name, approach, learning_rate, weight_decay, epochs, labeled_indices, train_dataloader_batch_size, training_pool, pool_dataloader, val_dataloader, patience)\n",
    "    \n",
    "        current_cycle += 1\n",
    "    return all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57a94687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 1/16\n",
      "-------------------------------------------------\n",
      "Choosing initial 16 samples randomly...\n",
      "\n",
      "Training and evaluating model using 16 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/miniconda3/envs/plm-active-learning/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "[Training]:  76%|███████▌  | 38/50 [00:16<00:05,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0436 | Val Loss: 0.2137 | SpearmanR: 0.3303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating model using 16 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  20%|██        | 10/50 [00:04<00:17,  2.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.1909 | Val Loss: 0.2235 | SpearmanR: 0.1096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 0 appended to results/03_bootstrap_ensemble/active_vs_standard_learning_curve.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  52%|█████▏    | 26/50 [00:11<00:10,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0488 | Val Loss: 0.3131 | SpearmanR: 0.2721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 25/25 [00:02<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:16<00:05,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0544 | Val Loss: 0.2670 | SpearmanR: 0.2994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 25/25 [00:02<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  38%|███▊      | 19/50 [00:08<00:13,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0753 | Val Loss: 0.1990 | SpearmanR: 0.0530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 25/25 [00:02<00:00, 11.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  58%|█████▊    | 29/50 [00:12<00:08,  2.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0348 | Val Loss: 0.2820 | SpearmanR: 0.2569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 25/25 [00:02<00:00, 12.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:14<00:07,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0447 | Val Loss: 0.2516 | SpearmanR: 0.3652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 25/25 [00:02<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 2/16\n",
      "-------------------------------------------------\n",
      "Saving variance distribution to results/02_mc_dropout/variances2.csv...\n",
      "Save complete.\n",
      "Selecting new data points...\n",
      "\n",
      "Training and evaluating model using 32 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  64%|██████▍   | 32/50 [00:14<00:08,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0495 | Val Loss: 0.2012 | SpearmanR: 0.3027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training and evaluating model using 32 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:   4%|▍         | 2/50 [00:01<00:30,  1.58it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      2\u001b[39m     MODEL_NAME,\n\u001b[32m      3\u001b[39m     APPROACH,\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     N_MODELS,\n\u001b[32m     10\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mget_learning_curves\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_n_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapproach\u001b[49m\u001b[43m=\u001b[49m\u001b[43mAPPROACH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpool_dataloader_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPOOL_BATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_MODELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresults/03_bootstrap_ensemble/active_vs_standard_learning_curve.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 85\u001b[39m, in \u001b[36mget_learning_curves\u001b[39m\u001b[34m(n_samples, initial_n_samples, n_samples_per_batch, model_name, approach, learning_rate, weight_decay, epochs, training_pool, train_dataloader_batch_size, pool_dataloader_batch_size, val_dataloader, test_dataloader, patience, n_models, results_path)\u001b[39m\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# standard\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining and evaluating model using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(labeled_indices)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m randomly selected samples...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m model_standard, _ = \u001b[43mrun_standard_finetuning\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabeled_indices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapproach\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m results_standard = test_model(model_standard, test_dataloader, return_results=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     87\u001b[39m results_standard = {\n\u001b[32m     88\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mchanging_var\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mn_samples\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     89\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mlocal_exp_idx\u001b[39m\u001b[33m'\u001b[39m: current_cycle-\u001b[32m1\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     92\u001b[39m     **results_standard\n\u001b[32m     93\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/strucbio_projects/plm_with_active_learning/pikh1_hma/scripts/campaigns.py:25\u001b[39m, in \u001b[36mrun_standard_finetuning\u001b[39m\u001b[34m(n_samples, approach, model_name, batch_size, learning_rate, weight_decay, epochs, training_pool, val_dataloader, patience)\u001b[39m\n\u001b[32m     22\u001b[39m train_dataloader = DataLoader(train_subset, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# train model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m model, history = \u001b[43minitialize_and_train_new_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapproach\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_history\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/strucbio_projects/plm_with_active_learning/pikh1_hma/scripts/training.py:98\u001b[39m, in \u001b[36minitialize_and_train_new_model\u001b[39m\u001b[34m(approach, model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history, checkpoint_path)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc=\u001b[33m\"\u001b[39m\u001b[33m[Training]\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     97\u001b[39m     train_loss = train_step(model, optimizer, train_dataloader)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     val_loss, spearmanr = \u001b[43mval_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspearman\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m     train_loss_history.append(train_loss)\n\u001b[32m    101\u001b[39m     val_loss_history.append(val_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/strucbio_projects/plm_with_active_learning/pikh1_hma/scripts/training.py:53\u001b[39m, in \u001b[36mval_step\u001b[39m\u001b[34m(model, val_dataloader, spearman)\u001b[39m\n\u001b[32m     50\u001b[39m preds = outputs.logits.squeeze() \u001b[38;5;66;03m# to make sure dimensions are the same for spearman\u001b[39;00m\n\u001b[32m     51\u001b[39m loss = outputs.loss\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m total_val_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m all_preds.append(preds.cpu())\n\u001b[32m     56\u001b[39m all_labels.append(labels.cpu())\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from scripts.config import (\n",
    "    MODEL_NAME,\n",
    "    APPROACH,\n",
    "    LEARNING_RATE,\n",
    "    WEIGHT_DECAY,\n",
    "    EPOCHS,\n",
    "    POOL_BATCH_SIZE,\n",
    "    PATIENCE,\n",
    "    N_MODELS,\n",
    ")\n",
    "\n",
    "get_learning_curves(\n",
    "    n_samples=256,\n",
    "    initial_n_samples=16,\n",
    "    n_samples_per_batch=16,\n",
    "    model_name=MODEL_NAME,\n",
    "    approach=APPROACH,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    epochs=EPOCHS,\n",
    "    training_pool=training_pool,\n",
    "    train_dataloader_batch_size=BATCH_SIZE,\n",
    "    pool_dataloader_batch_size=POOL_BATCH_SIZE,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    patience=PATIENCE,\n",
    "    n_models=N_MODELS,\n",
    "    results_path='results/03_bootstrap_ensemble/active_vs_standard_learning_curve.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16d644b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plm-active-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
