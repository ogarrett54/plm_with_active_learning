{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a496b305",
   "metadata": {},
   "source": [
    "# Active Fine-tuning of PLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743064de",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "- Trial three approaches for active fine-tuning of ESM2 on our Pikh1 HMA data\n",
    "    1. train an ensemble of models and use the mean and variance of their predictions to guide learning\n",
    "    2. use dropout layer during prediction, find mean and variance of predictions\n",
    "    3. mean variance estimation fine-tuning to predict two values with gaussian negative log-likelihood loss\n",
    "- Compare data efficiency between each method (that is, how many training labels are needed to achieve the same spearman r on a universal test set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4471d3",
   "metadata": {},
   "source": [
    "## Prepare data splits\n",
    "Starting data is from FACS of surface displayed Pikh1 HMA variants when exposed to 1 uM AVR-PikC. There are 3960 labels in this dataset, each with a full sequence and an enrichment score, roughly correlated with binding affinity. We'll load these into a torch dataset, then split into 80% train, 10% val, and 10% test. The training data will be what we use for all active learning loops, validated on the val set. The test set will be used as a universal final test set for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19d00765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_sequence</th>\n",
       "      <th>enrichment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>1.468796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GLKRIIVIKVAREGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.415944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GLKRIIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.389615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...</td>\n",
       "      <td>1.359651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...</td>\n",
       "      <td>1.343857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         aa_sequence  enrichment_score\n",
       "0  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...          1.468796\n",
       "1  GLKRIIVIKVAREGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.415944\n",
       "2  GLKRIIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.389615\n",
       "3  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRDKIEV...          1.359651\n",
       "4  GLKQKIVIKVAMEGNNCRSKAMALVASTGGVDSVALVGDLRGKIEV...          1.343857"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('avrpikC_full.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c9613c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = df.aa_sequence\n",
    "scores = df.enrichment_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afccfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class BindingDataset(Dataset):\n",
    "    def __init__(self, sequences, scores):\n",
    "        # make sure sequence and scores have the same length\n",
    "        assert len(sequences) == len(scores), f\"Sequences and scores must be of the same length.\\nNumber of sequences: {len(sequences)}\\nNumber of scores: {len(scores)}\"\n",
    "        self.sequences = sequences\n",
    "        self.scores = scores\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t12_35M_UR50D\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        label = torch.tensor(self.scores[idx], dtype=torch.float)\n",
    "\n",
    "        # tokenize the sequence\n",
    "        tokenized = self.tokenizer(\n",
    "            sequence,\n",
    "            max_length=80, # 78 residues + 2 extra tokens\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # return input_ids: attention masks, removing the batch dimension\n",
    "        inputs = {key: val.squeeze(0) for key, val in tokenized.items()}\n",
    "\n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99740828",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "full_dataset = BindingDataset(sequences, scores)\n",
    "\n",
    "# split the data into train, val, and test sets\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = int(0.1 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "training_pool, val_dataset, test_dataset = random_split(full_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# define dataloaders for val and test sets, train will be defined later for subsets\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d342c3",
   "metadata": {},
   "source": [
    "Code in this section was moved to modular scripts for later use: config.py, dataset.py, and data_utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3cdc9b",
   "metadata": {},
   "source": [
    "## Approach 1: Ensemble Predictions\n",
    "1. Initialize model 1: pretrained esm2 with a randomized binding head\n",
    "2. Train on an initial batch of 24 samples (test random and zero-shot predictions).\n",
    "    - Initial hyperparameters (note that during an actual active learning run, you can't change this in the middle of the campaign)\n",
    "        - optimizer: AdamW\n",
    "        - learning rate: 2e-5\n",
    "        - weight decay: 0.01\n",
    "        - early stopping\n",
    "3. Evaluate on validation set\n",
    "4. Evalutate on the rest of the available training pool\n",
    "5. Initialize model 2\n",
    "6. Repeat 2-5 until 5 models have been trained and used to evalutate\n",
    "7. Calculate variance of model predictions on each sequence in the training pool.\n",
    "8. Select the next 24 sequences with the highest variance.\n",
    "9. Reinitialize model 1 with pretrained esm2 and a freshly randomized binding head.\n",
    "10. Repeat ensemble training, evaluation, and acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25eff210",
   "metadata": {},
   "source": [
    "- Notes about alternative approaches for the baseline fine-tuning approach:\n",
    "    - Fine-tuning ESM2 is still under active research, and recent literature suggests that just using the CLS token for mutant effects may not be the best approach\n",
    "    - [ESM Effect](https://www.biorxiv.org/content/10.1101/2025.02.03.635741v1.full.pdf) details a framework for using the mutant token vectors as the basis for predicting mutant effects.\n",
    "        - Here, they use 35M model with last two layers unfrozen. They use the mutant tokens to predict mutant effects. They have a prediction head composed of two linear layers. However, their datasets are of deep mutational scans, so only one mutation. I would have to adapt this for higher numbers of mutations.\n",
    "            - to adapt it for a higher number of mutations, I could pool, concatenate, or use an attention mechanism\n",
    "- For now, I'm going to set up the active training loop using the standard CLS token approach (aka, what the AutoModelForSequenceClassification class does from the transformers library), but I will need to separately experiment with other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f789004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torch.nn import MSELoss\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.regression import SpearmanCorrCoef\n",
    "from transformers import logging\n",
    "\n",
    "logging.set_verbosity_error() # supress initialization warnings\n",
    "\n",
    "def initialize_HF_ESM2(model_name, learning_rate, weight_decay):\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 1)\n",
    "    # loss_fn = MSELoss() : HuggingFace automatically handles the loss\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    spearman = SpearmanCorrCoef()\n",
    "    return model, optimizer, spearman #,loss_fn\n",
    "\n",
    "def train_step(model, optimizer, train_dataloader):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    return avg_train_loss\n",
    "\n",
    "def val_step(model, val_dataloader, spearman):\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            preds = outputs.logits.squeeze() # to make sure dimensions are the same for spearman\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    spearmanr = spearman(all_preds, all_labels).item()\n",
    "\n",
    "    return avg_val_loss, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "143eab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_and_train_new_model(\n",
    "        model_name, \n",
    "        learning_rate, \n",
    "        weight_decay,\n",
    "        epochs, \n",
    "        train_dataloader, \n",
    "        val_dataloader, \n",
    "        patience=5,\n",
    "        return_history=False,\n",
    "        checkpoint_path=\"best_model.pth\"\n",
    "        ):\n",
    "    \n",
    "    model, optimizer, spearman = initialize_HF_ESM2(model_name, learning_rate, weight_decay)\n",
    "\n",
    "    # initialize variables for early stopping\n",
    "    best_val_spearman = -1\n",
    "    epochs_wo_improvement = 0\n",
    "\n",
    "    # initialize lists to store metrics\n",
    "    train_loss_history = []\n",
    "    val_loss_history = []\n",
    "    spearmanr_history = []\n",
    "\n",
    "    # main training loop\n",
    "    for epoch in tqdm(range(epochs), desc=\"[Training]\"):\n",
    "        train_loss = train_step(model, optimizer, train_dataloader)\n",
    "        val_loss, spearmanr = val_step(model, val_dataloader, spearman)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        val_loss_history.append(val_loss)\n",
    "        spearmanr_history.append(spearmanr)\n",
    "\n",
    "        # early stopping logic\n",
    "        if spearmanr > best_val_spearman:\n",
    "            best_val_spearman = spearmanr\n",
    "            epochs_wo_improvement = 0\n",
    "            # save the best model for later\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        else:\n",
    "            epochs_wo_improvement += 1\n",
    "        \n",
    "        if epochs_wo_improvement == patience:\n",
    "            print(f\"Early stopping triggered after {patience} epochs with no improvement.\")\n",
    "            break\n",
    "        \n",
    "    print(f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | SpearmanR: {spearmanr:.4f}')\n",
    "\n",
    "    # load the best model before output\n",
    "    model.load_state_dict(torch.load(checkpoint_path))\n",
    "\n",
    "    if return_history:\n",
    "        history = {\n",
    "            'train_loss': train_loss_history,\n",
    "            'val_loss': val_loss_history,\n",
    "            'spearmanr': spearmanr_history\n",
    "        }\n",
    "        return model, history\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce232e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "def acquire_new_batch(dataset, initial_batch_size, batch_size_to_acquire, labeled_indices, unlabeled_indices, acquisition_scores=None):\n",
    "    # if initial batch, when there are no acquisition scores, select randomly\n",
    "    if acquisition_scores is None:\n",
    "        initial_batch_size = min(initial_batch_size, len(unlabeled_indices))\n",
    "        indices_to_acquire = np.random.choice(unlabeled_indices, size=initial_batch_size, replace=False)\n",
    "    \n",
    "    # else select based on top acquisition scores\n",
    "    else:\n",
    "        # make sure we don't overshoot samples to acquire if on the final batch\n",
    "        batch_size_to_acquire = min(batch_size_to_acquire, len(acquisition_scores))\n",
    "        # get the indicies of the top acquisition scores (num of samples)\n",
    "        top_k_indices = acquisition_scores.topk(batch_size_to_acquire).indices\n",
    "        # use these to find the indicies that map back to the original dataset\n",
    "        indices_to_acquire = unlabeled_indices[top_k_indices.cpu().numpy()]\n",
    "    \n",
    "    # update the indices lists\n",
    "    labeled_indices = np.concatenate([labeled_indices, indices_to_acquire])\n",
    "    unlabeled_indices = np.setdiff1d(unlabeled_indices, indices_to_acquire, assume_unique=True)\n",
    "    \n",
    "    # create new subsets and dataloaders\n",
    "    train_subset = Subset(dataset, labeled_indices.tolist())\n",
    "    pool_subset = Subset(dataset, unlabeled_indices.tolist())\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    pool_dataloader = DataLoader(pool_subset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    return train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "131b5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_predictions(model, pool_dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        # iterate through pool loader\n",
    "        for inputs, labels in tqdm(pool_dataloader, desc=f\"[Surveying]\"):\n",
    "            # get model predictions, append them to list (num batches, batch size)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            preds = outputs.logits\n",
    "            all_preds.append(preds.cpu())\n",
    "    \n",
    "    # concat predictions from all batches for a single prediction tensor\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1705809",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ensemble(\n",
    "        n_models, \n",
    "        model_name, \n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        epochs,\n",
    "        train_dataloader, \n",
    "        pool_dataloader, \n",
    "        val_dataloader,\n",
    "        patience\n",
    "        ):\n",
    "    \n",
    "    # define list to store predictions as each model is trained then evaluated\n",
    "    ensemble_predictions = []\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        print(f\"\\nTraining Model {i+1}...\")\n",
    "        # set a changing manual seed\n",
    "        torch.manual_seed(i)\n",
    "        torch.cuda.manual_seed(i)\n",
    "\n",
    "        # initialize and train a new model\n",
    "        model = initialize_and_train_new_model(model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience)\n",
    "        \n",
    "        # get model predictions on pool dataloader, append to ensemble predictions list\n",
    "        pool_preds = get_model_predictions(model, pool_dataloader)\n",
    "        ensemble_predictions.append(pool_preds)\n",
    "\n",
    "    # stack ensemble predictions to create tensor of shape (n_models, n_unlabeled_samples)\n",
    "    ensemble_predictions = torch.stack(ensemble_predictions, dim=0)\n",
    "    print(\"Ensemble training complete, submitting predictions for next cycle.\")\n",
    "    # return list of ensemble predictions\n",
    "    return ensemble_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d105347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get acquisition scores (variance) given model predictions\n",
    "def get_acquisition_scores(ensemble_predictions):\n",
    "    # calculate variance for each index\n",
    "    variances = torch.var(ensemble_predictions, dim=0)\n",
    "    # return list of acquisition scores\n",
    "    return variances.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "794bb19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# run active learning campaign given num samples, num samples per batch\n",
    "def run_active_learning_campaign(\n",
    "        n_samples,\n",
    "        initial_n_samples,\n",
    "        n_samples_per_batch,\n",
    "        model_name, \n",
    "        learning_rate,\n",
    "        weight_decay,\n",
    "        epochs,\n",
    "        training_pool, \n",
    "        val_dataloader,\n",
    "        patience,\n",
    "        n_models\n",
    "        ):\n",
    "    # initialize index lists\n",
    "    total_pool_size = len(training_pool)\n",
    "    unlabeled_indices = np.arange(total_pool_size)\n",
    "    labeled_indices = np.array([], dtype=np.int64)\n",
    "\n",
    "    ensemble_predictions = None\n",
    "    current_cycle = 1\n",
    "    \n",
    "    while len(labeled_indices) < n_samples and len(unlabeled_indices) > 0:\n",
    "        print(f\"\\nCycle {current_cycle}/{int(np.ceil((n_samples-initial_n_samples)/n_samples_per_batch)) + 1}\\n-------------------------------------------------\")\n",
    "\n",
    "        # on the first cycle, choose random samples of initial_n_samples size\n",
    "        if ensemble_predictions is None:\n",
    "            print(f\"Choosing initial {initial_n_samples} samples randomly...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=None\n",
    "            )\n",
    "        # each other time, use the n_samples_per_batch with acquisition scores to select\n",
    "        else:\n",
    "            scores = get_acquisition_scores(ensemble_predictions)\n",
    "            print(f\"Selecting new data points...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=scores\n",
    "            )\n",
    "        \n",
    "        if len(unlabeled_indices) == 0:\n",
    "            print(\"Unlabeled pool is empty. Proceeding to final model training.\")\n",
    "            break\n",
    "\n",
    "        print(\"Starting ensemble training and pool evaluation...\")\n",
    "        ensemble_predictions = train_ensemble(n_models, model_name, learning_rate, weight_decay, epochs, train_dataloader, pool_dataloader, val_dataloader, patience)\n",
    "\n",
    "        current_cycle += 1\n",
    "\n",
    "    print(\"\\nActive learning campaign complete.\")\n",
    "    print(f\"Training final model on {len(labeled_indices)} actively selected samples...\")\n",
    "    model, history = initialize_and_train_new_model(model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history=True)\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9977554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 6/3\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  19%|█▉        | 19/100 [00:09<00:40,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.0612 | Val Loss: 0.1342 | SpearmanR: 0.5872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 149.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  11%|█         | 11/100 [00:05<00:44,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.1146 | Val Loss: 0.2053 | SpearmanR: 0.5294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 152.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  21%|██        | 21/100 [00:10<00:40,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.0607 | Val Loss: 0.1454 | SpearmanR: 0.5548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 152.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  18%|█▊        | 18/100 [00:08<00:39,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.0705 | Val Loss: 0.1532 | SpearmanR: 0.5010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 155.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:   9%|▉         | 9/100 [00:04<00:45,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.1030 | Val Loss: 0.2079 | SpearmanR: 0.4205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 154.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Active learning campaign complete.\n",
      "Training final model on 144 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  22%|██▏       | 22/100 [00:10<00:38,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.0614 | Val Loss: 0.1512 | SpearmanR: 0.5417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/esm2_t6_8M_UR50D\"\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "N_MODELS = 5\n",
    "\n",
    "model_active, history_active = run_active_learning_campaign(\n",
    "        n_samples = 144,\n",
    "        initial_n_samples = 72,\n",
    "        n_samples_per_batch = 24,\n",
    "        model_name = MODEL_NAME, \n",
    "        learning_rate = LEARNING_RATE,\n",
    "        weight_decay = WEIGHT_DECAY,\n",
    "        epochs = EPOCHS,\n",
    "        training_pool = training_pool, \n",
    "        val_dataloader = val_dataloader,\n",
    "        patience = PATIENCE,\n",
    "        n_models = N_MODELS\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4747322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run standard fine-tuning procedure given num samples\n",
    "def run_standard_finetuning(\n",
    "        n_samples, \n",
    "        model_name, \n",
    "        learning_rate, \n",
    "        weight_decay, \n",
    "        epochs, \n",
    "        training_pool, \n",
    "        val_dataloader,\n",
    "        patience,\n",
    "        ):\n",
    "    # get dataloader of random train data\n",
    "    random_indices = torch.randperm(len(training_pool))[:n_samples].tolist()\n",
    "    train_subset = Subset(training_pool, random_indices)\n",
    "    train_dataloader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    # train model\n",
    "    model, history = initialize_and_train_new_model(model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history=True)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "88769ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/miniconda3/envs/ml/lib/python3.11/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "[Training]:  11%|█         | 11/100 [00:06<00:52,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 5 epochs with no improvement.\n",
      "Train Loss: 0.1754 | Val Loss: 0.1673 | SpearmanR: 0.4616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_standard, history_standard = run_standard_finetuning(\n",
    "        n_samples = 144,\n",
    "        model_name = MODEL_NAME, \n",
    "        learning_rate = LEARNING_RATE,\n",
    "        weight_decay = WEIGHT_DECAY,\n",
    "        epochs = EPOCHS,\n",
    "        training_pool = training_pool, \n",
    "        val_dataloader = val_dataloader,\n",
    "        patience = PATIENCE\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "795f0aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.regression import SpearmanCorrCoef, PearsonCorrCoef, MeanSquaredError\n",
    "\n",
    "def test_model(model, test_dataloader, return_results=False):\n",
    "    # Initialize metrics\n",
    "    spearman = SpearmanCorrCoef().to(device)\n",
    "    pearson = PearsonCorrCoef().to(device)\n",
    "    mse = MeanSquaredError().to(device)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_test_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for inputs, labels in tqdm(test_dataloader, desc=\"[Testing]\"):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            preds = outputs.logits.squeeze()\n",
    "            loss = outputs.loss\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    # Concatenate all predictions and labels from all batches\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    # Calculate final metrics\n",
    "    avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "    spearmanr = spearman(all_preds, all_labels).item()\n",
    "    pearsonr = pearson(all_preds, all_labels).item()\n",
    "    final_mse = mse(all_preds, all_labels).item()\n",
    "\n",
    "    if return_results:\n",
    "        results = {\n",
    "            \"avg_test_loss\": avg_test_loss,\n",
    "            \"spearmanr\": spearmanr,\n",
    "            \"pearsonr\": pearsonr,\n",
    "            \"final_mse\": final_mse\n",
    "        }\n",
    "        return results\n",
    "    else:\n",
    "        # Print the report\n",
    "        print(f\"Spearman's Rho: {spearmanr:.4f}\")\n",
    "        print(f\"Pearson's Rho: {pearsonr:.4f}\")\n",
    "        print(f\"Mean Squared Error (MSE): {final_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a469b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]:   0%|          | 0/33 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 33/33 [00:00<00:00, 76.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1396\n",
      "Spearman's Rho: 0.5594\n",
      "Pearson's Rho: 0.5615\n",
      "Mean Squared Error (MSE): 0.1396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model_active, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e11a0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 33/33 [00:00<00:00, 159.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1576\n",
      "Spearman's Rho: 0.5311\n",
      "Pearson's Rho: 0.4833\n",
      "Mean Squared Error (MSE): 0.1576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(model_standard, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1d0898f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.292849</td>\n",
       "      <td>0.237494</td>\n",
       "      <td>0.071654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.260006</td>\n",
       "      <td>0.238660</td>\n",
       "      <td>0.171154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256437</td>\n",
       "      <td>0.232513</td>\n",
       "      <td>0.250838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.248370</td>\n",
       "      <td>0.258319</td>\n",
       "      <td>0.398959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.253237</td>\n",
       "      <td>0.201234</td>\n",
       "      <td>0.361160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.216148</td>\n",
       "      <td>0.194606</td>\n",
       "      <td>0.412462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.195385</td>\n",
       "      <td>0.186426</td>\n",
       "      <td>0.433561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.155915</td>\n",
       "      <td>0.227530</td>\n",
       "      <td>0.436336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.150174</td>\n",
       "      <td>0.200697</td>\n",
       "      <td>0.455136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.172423</td>\n",
       "      <td>0.166411</td>\n",
       "      <td>0.464650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.126156</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>0.494658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.109330</td>\n",
       "      <td>0.161752</td>\n",
       "      <td>0.509152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.098827</td>\n",
       "      <td>0.171701</td>\n",
       "      <td>0.504017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.088888</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>0.518565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.162377</td>\n",
       "      <td>0.516788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.086911</td>\n",
       "      <td>0.155397</td>\n",
       "      <td>0.519147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.079412</td>\n",
       "      <td>0.150213</td>\n",
       "      <td>0.521050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.075060</td>\n",
       "      <td>0.158003</td>\n",
       "      <td>0.525110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.068623</td>\n",
       "      <td>0.159686</td>\n",
       "      <td>0.527794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.070014</td>\n",
       "      <td>0.228334</td>\n",
       "      <td>0.521715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.092133</td>\n",
       "      <td>0.174017</td>\n",
       "      <td>0.533355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.074976</td>\n",
       "      <td>0.144712</td>\n",
       "      <td>0.543452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.061408</td>\n",
       "      <td>0.151193</td>\n",
       "      <td>0.541705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train_loss  val_loss  spearmanr\n",
       "0     0.292849  0.237494   0.071654\n",
       "1     0.260006  0.238660   0.171154\n",
       "2     0.256437  0.232513   0.250838\n",
       "3     0.248370  0.258319   0.398959\n",
       "4     0.253237  0.201234   0.361160\n",
       "5     0.216148  0.194606   0.412462\n",
       "6     0.195385  0.186426   0.433561\n",
       "7     0.155915  0.227530   0.436336\n",
       "8     0.150174  0.200697   0.455136\n",
       "9     0.172423  0.166411   0.464650\n",
       "10    0.126156  0.158798   0.494658\n",
       "11    0.109330  0.161752   0.509152\n",
       "12    0.098827  0.171701   0.504017\n",
       "13    0.088888  0.149980   0.518565\n",
       "14    0.089300  0.162377   0.516788\n",
       "15    0.086911  0.155397   0.519147\n",
       "16    0.079412  0.150213   0.521050\n",
       "17    0.075060  0.158003   0.525110\n",
       "18    0.068623  0.159686   0.527794\n",
       "19    0.070014  0.228334   0.521715\n",
       "20    0.092133  0.174017   0.533355\n",
       "21    0.074976  0.144712   0.543452\n",
       "22    0.061408  0.151193   0.541705"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_active_results = pd.DataFrame(history_active)\n",
    "df_standard_results = pd.DataFrame(history_standard)\n",
    "\n",
    "df_active_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918609eb",
   "metadata": {},
   "source": [
    "- More notes\n",
    "    - This simulation plays out in a defined pool of samples, how will this work in the real world, where there's practically infinite options?\n",
    "        - first, you need to define the limits of the space. probably something like a limited number of mutations per sequence, and perhaps a distribution of those mutation numbers in your final set\n",
    "        - boring approach: generate mutants and evaluate ensemble on mutants for a defined amount of time, select the highest variance mutants from that set.\n",
    "        - cool approach: train an adversarial model that learns how to optimally challenge the plm model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23540acd",
   "metadata": {},
   "source": [
    "Anyways, now that we have the active learning loop working, let's start running some experiments to better understand how different parameters effect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "# define the experiment conditions as a list of dicts with the hyperparameters, and \n",
    "# two extra entries, one with the parameter currently changing, and the other with \n",
    "# the local experiment index\n",
    "\n",
    "# define a results list (will be a list of dicts)\n",
    "def run_experiments(experiments, training_pool, val_dataloader, test_dataloader, results_path='active_vs_standard_results.csv'):\n",
    "    results_path = Path(results_path)\n",
    "\n",
    "    # Load existing results if the file exists, otherwise start with a fresh DataFrame.\n",
    "    if results_path.exists():\n",
    "        all_results_df = pd.read_csv(results_path)\n",
    "    else:\n",
    "        all_results_df = pd.DataFrame()\n",
    "\n",
    "    final_results = []\n",
    "    # loop through experiment conditions\n",
    "    for i, exp in enumerate(experiments):\n",
    "        print(f\"\\nEXPERIMENT {i}\\n~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\")\n",
    "        # run active learning campaign, ignore history for now\n",
    "        params_active = {\n",
    "            \"n_samples\": exp[\"n_samples\"],\n",
    "            \"initial_n_samples\": exp[\"initial_n_samples\"],\n",
    "            \"n_samples_per_batch\": exp[\"n_samples_per_batch\"],\n",
    "            \"model_name\": exp[\"model_name\"], \n",
    "            \"learning_rate\": exp[\"learning_rate\"],\n",
    "            \"weight_decay\": exp[\"weight_decay\"],\n",
    "            \"epochs\": exp[\"epochs\"],\n",
    "            \"patience\": exp[\"patience\"],\n",
    "            \"n_models\": exp[\"n_models\"]\n",
    "        }\n",
    "        model, _ = run_active_learning_campaign(\n",
    "            **params_active, \n",
    "            training_pool=training_pool, \n",
    "            val_dataloader=val_dataloader\n",
    "            )\n",
    "        # run model on test set, returning results\n",
    "        results = test_model(model, test_dataloader, return_results=True)\n",
    "        # add to the results dict the changing var, local experiment idx, the value of the changing var, and training method active\n",
    "        results = {\n",
    "            'changing_var': exp['changing_var'],\n",
    "            'local_exp_idx': exp['local_exp_idx'],\n",
    "            'value': params_active[exp['changing_var']],\n",
    "            'training_method': 'active',\n",
    "            **results\n",
    "        }\n",
    "        # append dict to results list\n",
    "        final_results.append(results)\n",
    "\n",
    "        # run standard fine-tuning, ignore history for now\n",
    "        print(f\"\\nTraining using standard approach, with {exp['n_samples_per_batch']} randomly selected samples...\")\n",
    "        params_standard = {\n",
    "            \"n_samples\": exp[\"n_samples\"],\n",
    "            \"model_name\": exp[\"model_name\"], \n",
    "            \"learning_rate\": exp[\"learning_rate\"],\n",
    "            \"weight_decay\": exp[\"weight_decay\"],\n",
    "            \"epochs\": exp[\"epochs\"],\n",
    "            \"patience\": exp[\"patience\"],\n",
    "        }\n",
    "        model, _ = run_standard_finetuning(\n",
    "            **params_standard, \n",
    "            training_pool=training_pool, \n",
    "            val_dataloader=val_dataloader\n",
    "            )\n",
    "        # run model on test set, returning results\n",
    "        results = test_model(model, test_dataloader, return_results=True)\n",
    "        # add to the results dict the changing var, local experiment idx, the value of the changing var, and training method standard\n",
    "        results = {\n",
    "            'changing_var': exp['changing_var'],\n",
    "            'local_exp_idx': exp['local_exp_idx'],\n",
    "            'value': params_active[exp['changing_var']],\n",
    "            'training_method': 'standard',\n",
    "            **results\n",
    "        }\n",
    "        # append dict to results list\n",
    "        final_results.append(results)\n",
    "\n",
    "        # save to disk each time to save progress\n",
    "        results_df = pd.DataFrame(final_results)\n",
    "        all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)\n",
    "        all_results_df.to_csv(results_path, index=False)\n",
    "        print(f\"Progress for experiment {i} appended to {results_path}\")\n",
    "    return all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3aefa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_initial_n = [\n",
    "    {\n",
    "        \"changing_var\": \"n_samples\",\n",
    "        \"local_exp_idx\": 0,\n",
    "        \"n_samples\": 48,\n",
    "        \"initial_n_samples\": 24,\n",
    "        \"n_samples_per_batch\": 24,\n",
    "        \"model_name\": \"facebook/esm2_t6_8M_UR50D\", \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"n_models\": 5\n",
    "    },\n",
    "    {\n",
    "        \"changing_var\": \"n_samples\",\n",
    "        \"local_exp_idx\": 1,\n",
    "        \"n_samples\": 72,\n",
    "        \"initial_n_samples\": 24,\n",
    "        \"n_samples_per_batch\": 24,\n",
    "        \"model_name\": \"facebook/esm2_t6_8M_UR50D\", \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"n_models\": 5\n",
    "    },\n",
    "    {\n",
    "        \"changing_var\": \"n_samples\",\n",
    "        \"local_exp_idx\": 2,\n",
    "        \"n_samples\": 96,\n",
    "        \"initial_n_samples\": 24,\n",
    "        \"n_samples_per_batch\": 24,\n",
    "        \"model_name\": \"facebook/esm2_t6_8M_UR50D\", \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"n_models\": 5\n",
    "    },\n",
    "    {\n",
    "        \"changing_var\": \"n_samples\",\n",
    "        \"local_exp_idx\": 3,\n",
    "        \"n_samples\": 144,\n",
    "        \"initial_n_samples\": 24,\n",
    "        \"n_samples_per_batch\": 24,\n",
    "        \"model_name\": \"facebook/esm2_t6_8M_UR50D\", \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"n_models\": 5\n",
    "    },\n",
    "    {\n",
    "        \"changing_var\": \"n_samples\",\n",
    "        \"local_exp_idx\": 4,\n",
    "        \"n_samples\": 240,\n",
    "        \"initial_n_samples\": 24,\n",
    "        \"n_samples_per_batch\": 24,\n",
    "        \"model_name\": \"facebook/esm2_t6_8M_UR50D\", \n",
    "        \"learning_rate\": 2e-5,\n",
    "        \"weight_decay\": 0.01,\n",
    "        \"epochs\": 50,\n",
    "        \"patience\": 10,\n",
    "        \"n_models\": 5\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 4/4\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:26<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0043 | Val Loss: 0.1255 | SpearmanR: 0.6381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:00<00:00, 1658.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  76%|███████▌  | 38/50 [00:21<00:06,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0178 | Val Loss: 0.1302 | SpearmanR: 0.6569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 126.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:24<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0086 | Val Loss: 0.1421 | SpearmanR: 0.6605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 131.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  70%|███████   | 35/50 [00:17<00:07,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0259 | Val Loss: 0.1164 | SpearmanR: 0.6514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:01<00:00, 126.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:21<00:07,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0157 | Val Loss: 0.1068 | SpearmanR: 0.6706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 252/252 [00:02<00:00, 116.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Active learning campaign complete.\n",
      "Training final model on 144 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  78%|███████▊  | 39/50 [00:22<00:06,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0182 | Val Loss: 0.1454 | SpearmanR: 0.6433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 33/33 [00:00<00:00, 116.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training using standard approach, with 24 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  86%|████████▌ | 43/50 [00:23<00:03,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0232 | Val Loss: 0.1222 | SpearmanR: 0.6210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 33/33 [00:00<00:00, 122.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 1 appended to active_vs_standard_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>changing_var</th>\n",
       "      <th>local_exp_idx</th>\n",
       "      <th>value</th>\n",
       "      <th>training_method</th>\n",
       "      <th>avg_test_loss</th>\n",
       "      <th>spearmanr</th>\n",
       "      <th>pearsonr</th>\n",
       "      <th>final_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>initial_n_samples</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>active</td>\n",
       "      <td>0.152872</td>\n",
       "      <td>0.615488</td>\n",
       "      <td>0.619794</td>\n",
       "      <td>0.152872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>initial_n_samples</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.145488</td>\n",
       "      <td>0.505765</td>\n",
       "      <td>0.539804</td>\n",
       "      <td>0.145488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>initial_n_samples</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>active</td>\n",
       "      <td>0.114177</td>\n",
       "      <td>0.666418</td>\n",
       "      <td>0.684209</td>\n",
       "      <td>0.114177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>initial_n_samples</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.119180</td>\n",
       "      <td>0.631235</td>\n",
       "      <td>0.642157</td>\n",
       "      <td>0.119180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        changing_var  local_exp_idx  value training_method  avg_test_loss  \\\n",
       "0  initial_n_samples              1     48          active       0.152872   \n",
       "1  initial_n_samples              1     48        standard       0.145488   \n",
       "2  initial_n_samples              2     72          active       0.114177   \n",
       "3  initial_n_samples              2     72        standard       0.119180   \n",
       "\n",
       "   spearmanr  pearsonr  final_mse  \n",
       "0   0.615488  0.619794   0.152872  \n",
       "1   0.505765  0.539804   0.145488  \n",
       "2   0.666418  0.684209   0.114177  \n",
       "3   0.631235  0.642157   0.119180  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_experiments(experiments_initial_n, training_pool, val_dataloader, test_dataloader, results_path=\"results/01_basic_ensemble/active_vs_standard.results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3b8a42",
   "metadata": {},
   "source": [
    "The main benefit of active learning can be seen in the learning curve, but as I have it set up right now, if I were to experiment with \"n_samples\", I would run a lot of unnecessary compute. I'll need to modify my active learning campaign function to test the model and output its results after each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71c18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_curves(\n",
    "        n_samples,\n",
    "        initial_n_samples,\n",
    "        n_samples_per_batch,\n",
    "        model_name, \n",
    "        learning_rate, \n",
    "        weight_decay, \n",
    "        epochs, \n",
    "        training_pool, \n",
    "        val_dataloader, \n",
    "        test_dataloader,\n",
    "        patience=5,\n",
    "        n_models=5,\n",
    "        results_path=\"active_vs_standard_learning_curves.csv\"\n",
    "):\n",
    "    results_path = Path(results_path)\n",
    "\n",
    "    # Load existing results if the file exists, otherwise start with a fresh DataFrame.\n",
    "    if results_path.exists():\n",
    "        all_results_df = pd.read_csv(results_path)\n",
    "    else:\n",
    "        all_results_df = pd.DataFrame()\n",
    "    \n",
    "    total_pool_size = len(training_pool)\n",
    "    unlabeled_indices = np.arange(total_pool_size)\n",
    "    labeled_indices = np.array([], dtype=np.int64)\n",
    "\n",
    "    ensemble_predictions = None\n",
    "    current_cycle = 1\n",
    "    total_cycles = int(np.ceil((n_samples-initial_n_samples)/n_samples_per_batch)) + 1\n",
    "    \n",
    "    while len(labeled_indices) < n_samples and len(unlabeled_indices) > 0:\n",
    "        print(f\"\\nCycle {current_cycle}/{total_cycles}\\n-------------------------------------------------\")\n",
    "\n",
    "        # on the first cycle, choose random samples of initial_n_samples size\n",
    "        if ensemble_predictions is None:\n",
    "            print(f\"Choosing initial {initial_n_samples} samples randomly...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=None\n",
    "            )\n",
    "        # each other time, use the n_samples_per_batch with acquisition scores to select\n",
    "        else:\n",
    "            scores = get_acquisition_scores(ensemble_predictions)\n",
    "            print(f\"Selecting new data points...\")\n",
    "            train_dataloader, pool_dataloader, labeled_indices, unlabeled_indices = acquire_new_batch(\n",
    "                training_pool, initial_n_samples, n_samples_per_batch, labeled_indices, unlabeled_indices, acquisition_scores=scores\n",
    "            )\n",
    "        \n",
    "        # give message when loop ends\n",
    "        if len(unlabeled_indices) == 0:\n",
    "            print(\"Unlabeled pool is empty. Proceeding to final model training.\")\n",
    "            break\n",
    "        \n",
    "        # evaluate active vs standard\n",
    "        final_results = []\n",
    "\n",
    "        # active\n",
    "        print(f\"\\nTraining and evaluating model using {len(labeled_indices)} actively selected samples...\")\n",
    "        model_active = initialize_and_train_new_model(model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history=False)\n",
    "        results_active = test_model(model_active, test_dataloader, return_results=True)\n",
    "        results_active = {\n",
    "            'changing_var': 'n_samples',\n",
    "            'local_exp_idx': current_cycle-1,\n",
    "            'value': len(labeled_indices),\n",
    "            'training_method': 'active',\n",
    "            **results_active\n",
    "        }\n",
    "        final_results.append(results_active)\n",
    "\n",
    "        # standard\n",
    "        print(f\"\\nTraining and evaluating model using {len(labeled_indices)} randomly selected samples...\")\n",
    "        model_standard, _ = run_standard_finetuning(len(labeled_indices), model_name, learning_rate, weight_decay, epochs, training_pool, val_dataloader, patience)\n",
    "        results_standard = test_model(model_standard, test_dataloader, return_results=True)\n",
    "        results_standard = {\n",
    "            'changing_var': 'n_samples',\n",
    "            'local_exp_idx': current_cycle-1,\n",
    "            'value': len(labeled_indices),\n",
    "            'training_method': 'standard',\n",
    "            **results_standard\n",
    "        }\n",
    "        final_results.append(results_standard)\n",
    "\n",
    "        # save to disk each time to save progress\n",
    "        results_df = pd.DataFrame(final_results)\n",
    "        all_results_df = pd.concat([all_results_df, results_df], ignore_index=True)\n",
    "        all_results_df.to_csv(results_path, index=False)\n",
    "        print(f\"Progress for experiment {current_cycle-1} appended to {results_path}\")\n",
    "\n",
    "        # if it's the last cycle, skip ensemble predictions\n",
    "        if (current_cycle == total_cycles):\n",
    "            print(\"Experiments complete.\")\n",
    "            break\n",
    "\n",
    "        print(\"Starting ensemble training and pool evaluation...\")\n",
    "        ensemble_predictions = train_ensemble(n_models, model_name, learning_rate, weight_decay, epochs, train_dataloader, pool_dataloader, val_dataloader, patience)\n",
    "\n",
    "        current_cycle += 1\n",
    "    return all_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb27a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/miniconda3/envs/plm-active-learning/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cycle 1/64\n",
      "-------------------------------------------------\n",
      "Choosing initial 16 samples randomly...\n",
      "Training and evaluating model using 16 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  62%|██████▏   | 31/50 [00:16<00:09,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0532 | Val Loss: 0.1986 | SpearmanR: 0.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 16 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:25<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0111 | Val Loss: 0.2710 | SpearmanR: 0.2951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 0 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  94%|█████████▍| 47/50 [00:28<00:01,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0038 | Val Loss: 0.2065 | SpearmanR: 0.3113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 197/197 [00:02<00:00, 72.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:24<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0080 | Val Loss: 0.2154 | SpearmanR: 0.2177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 197/197 [00:02<00:00, 72.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:24<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032 | Val Loss: 0.2274 | SpearmanR: 0.3400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 197/197 [00:02<00:00, 71.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:14<00:06,  2.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0454 | Val Loss: 0.2249 | SpearmanR: 0.2186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 197/197 [00:02<00:00, 71.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:20<00:00,  2.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0055 | Val Loss: 0.2274 | SpearmanR: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 197/197 [00:02<00:00, 71.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 2/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 32 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:14<00:07,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0247 | Val Loss: 0.2141 | SpearmanR: 0.3016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 32 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0092 | Val Loss: 0.1871 | SpearmanR: 0.4336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 1 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0148 | Val Loss: 0.2006 | SpearmanR: 0.3834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 196/196 [00:02<00:00, 71.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0074 | Val Loss: 0.2133 | SpearmanR: 0.3980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 196/196 [00:02<00:00, 71.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  78%|███████▊  | 39/50 [00:17<00:04,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0584 | Val Loss: 0.1947 | SpearmanR: 0.3315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 196/196 [00:02<00:00, 71.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  20%|██        | 10/50 [00:04<00:18,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.1826 | Val Loss: 0.2157 | SpearmanR: 0.0660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 196/196 [00:02<00:00, 71.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0233 | Val Loss: 0.1966 | SpearmanR: 0.4295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 196/196 [00:02<00:00, 71.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 3/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 48 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  48%|████▊     | 24/50 [00:11<00:12,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0988 | Val Loss: 0.1806 | SpearmanR: 0.2663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 48 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  62%|██████▏   | 31/50 [00:15<00:09,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0344 | Val Loss: 0.1873 | SpearmanR: 0.4366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 2 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  72%|███████▏  | 36/50 [00:17<00:06,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0305 | Val Loss: 0.1922 | SpearmanR: 0.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 195/195 [00:02<00:00, 71.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:23<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0129 | Val Loss: 0.2068 | SpearmanR: 0.4183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 195/195 [00:02<00:00, 71.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:16<00:08,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0425 | Val Loss: 0.2212 | SpearmanR: 0.2750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 195/195 [00:02<00:00, 72.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0408 | Val Loss: 0.1813 | SpearmanR: 0.3629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 195/195 [00:02<00:00, 73.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:23<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0165 | Val Loss: 0.1887 | SpearmanR: 0.3988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 195/195 [00:02<00:00, 72.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 4/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 64 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  64%|██████▍   | 32/50 [00:16<00:09,  1.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0420 | Val Loss: 0.1707 | SpearmanR: 0.3830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 64 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:25<00:00,  1.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0082 | Val Loss: 0.1595 | SpearmanR: 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 3 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  80%|████████  | 40/50 [00:20<00:05,  1.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0399 | Val Loss: 0.1793 | SpearmanR: 0.3419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 194/194 [00:02<00:00, 72.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  62%|██████▏   | 31/50 [00:16<00:09,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0477 | Val Loss: 0.1749 | SpearmanR: 0.4240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 194/194 [00:02<00:00, 72.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  48%|████▊     | 24/50 [00:12<00:13,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0810 | Val Loss: 0.1765 | SpearmanR: 0.4162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 194/194 [00:02<00:00, 72.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:25<00:00,  1.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0228 | Val Loss: 0.1700 | SpearmanR: 0.4219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 194/194 [00:02<00:00, 72.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:19<00:06,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0267 | Val Loss: 0.1801 | SpearmanR: 0.3839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 194/194 [00:02<00:00, 72.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 5/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 80 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  46%|████▌     | 23/50 [00:12<00:15,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0847 | Val Loss: 0.1697 | SpearmanR: 0.5016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 80 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  44%|████▍     | 22/50 [00:12<00:15,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0954 | Val Loss: 0.2698 | SpearmanR: 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 4 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:20<00:07,  1.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0553 | Val Loss: 0.1523 | SpearmanR: 0.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 193/193 [00:02<00:00, 72.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  70%|███████   | 35/50 [00:19<00:08,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0502 | Val Loss: 0.1516 | SpearmanR: 0.4617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 193/193 [00:02<00:00, 72.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:26<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0285 | Val Loss: 0.1591 | SpearmanR: 0.5433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 193/193 [00:02<00:00, 71.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:27<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0219 | Val Loss: 0.1666 | SpearmanR: 0.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 193/193 [00:02<00:00, 72.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  76%|███████▌  | 38/50 [00:21<00:06,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0259 | Val Loss: 0.1717 | SpearmanR: 0.4413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 193/193 [00:02<00:00, 72.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 6/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 96 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0151 | Val Loss: 0.1551 | SpearmanR: 0.5262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 73.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 96 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:28<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0140 | Val Loss: 0.1314 | SpearmanR: 0.6052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 5 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:17<00:11,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0404 | Val Loss: 0.1447 | SpearmanR: 0.5293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 192/192 [00:02<00:00, 72.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  64%|██████▍   | 32/50 [00:18<00:10,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0403 | Val Loss: 0.1606 | SpearmanR: 0.4584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 192/192 [00:02<00:00, 71.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  62%|██████▏   | 31/50 [00:18<00:11,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0561 | Val Loss: 0.1664 | SpearmanR: 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 192/192 [00:02<00:00, 71.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:26<00:02,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0231 | Val Loss: 0.1736 | SpearmanR: 0.4214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 192/192 [00:02<00:00, 72.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  42%|████▏     | 21/50 [00:12<00:17,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0818 | Val Loss: 0.1743 | SpearmanR: 0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 192/192 [00:02<00:00, 72.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 7/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 112 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  46%|████▌     | 23/50 [00:14<00:16,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0813 | Val Loss: 0.1691 | SpearmanR: 0.4151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 112 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  76%|███████▌  | 38/50 [00:23<00:07,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0423 | Val Loss: 0.1358 | SpearmanR: 0.5701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 6 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  70%|███████   | 35/50 [00:22<00:09,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0653 | Val Loss: 0.1622 | SpearmanR: 0.5083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 191/191 [00:02<00:00, 72.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:21<00:09,  1.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0354 | Val Loss: 0.1543 | SpearmanR: 0.5034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 191/191 [00:02<00:00, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:21<00:10,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0590 | Val Loss: 0.1999 | SpearmanR: 0.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 191/191 [00:02<00:00, 71.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  46%|████▌     | 23/50 [00:14<00:17,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0975 | Val Loss: 0.1574 | SpearmanR: 0.3849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 191/191 [00:02<00:00, 72.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  44%|████▍     | 22/50 [00:14<00:18,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.1261 | Val Loss: 0.1665 | SpearmanR: 0.4696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 191/191 [00:02<00:00, 72.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 8/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 128 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:37<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0340 | Val Loss: 0.1863 | SpearmanR: 0.4814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 128 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:38<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0117 | Val Loss: 0.1383 | SpearmanR: 0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 73.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 7 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  52%|█████▏    | 26/50 [00:20<00:18,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0729 | Val Loss: 0.1497 | SpearmanR: 0.5147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 190/190 [00:02<00:00, 72.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:25<00:08,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0260 | Val Loss: 0.1692 | SpearmanR: 0.5013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 190/190 [00:02<00:00, 71.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:29<00:02,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0283 | Val Loss: 0.1684 | SpearmanR: 0.5248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 190/190 [00:02<00:00, 71.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:30<00:02,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0348 | Val Loss: 0.1707 | SpearmanR: 0.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 190/190 [00:02<00:00, 72.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  72%|███████▏  | 36/50 [00:23<00:09,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0374 | Val Loss: 0.1759 | SpearmanR: 0.4864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 190/190 [00:02<00:00, 72.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 9/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 144 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  98%|█████████▊| 49/50 [00:33<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0116 | Val Loss: 0.1714 | SpearmanR: 0.4997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 144 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:34<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0144 | Val Loss: 0.1306 | SpearmanR: 0.6410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 8 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:21<00:14,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0424 | Val Loss: 0.1649 | SpearmanR: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 189/189 [00:02<00:00, 71.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:33<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0117 | Val Loss: 0.1694 | SpearmanR: 0.5315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 189/189 [00:02<00:00, 72.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:33<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0240 | Val Loss: 0.1549 | SpearmanR: 0.5308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 189/189 [00:02<00:00, 72.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  70%|███████   | 35/50 [00:24<00:10,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0308 | Val Loss: 0.1734 | SpearmanR: 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 189/189 [00:02<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:22<00:11,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0700 | Val Loss: 0.1735 | SpearmanR: 0.5098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 189/189 [00:02<00:00, 71.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 10/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 160 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  88%|████████▊ | 44/50 [00:31<00:04,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0272 | Val Loss: 0.1456 | SpearmanR: 0.5375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 160 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:33<00:02,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0211 | Val Loss: 0.1360 | SpearmanR: 0.6077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 9 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  48%|████▊     | 24/50 [00:17<00:19,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0389 | Val Loss: 0.1603 | SpearmanR: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 188/188 [00:02<00:00, 72.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  62%|██████▏   | 31/50 [00:22<00:13,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0346 | Val Loss: 0.1535 | SpearmanR: 0.5161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 188/188 [00:02<00:00, 71.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:35<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0163 | Val Loss: 0.1536 | SpearmanR: 0.5291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 188/188 [00:02<00:00, 71.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:35<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0155 | Val Loss: 0.1443 | SpearmanR: 0.5257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 188/188 [00:02<00:00, 71.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:22<00:14,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0387 | Val Loss: 0.1483 | SpearmanR: 0.5399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 188/188 [00:02<00:00, 71.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 11/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 176 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:34<00:03,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0177 | Val Loss: 0.1429 | SpearmanR: 0.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 176 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:37<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0159 | Val Loss: 0.1196 | SpearmanR: 0.6747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 10 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  82%|████████▏ | 41/50 [00:30<00:06,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0309 | Val Loss: 0.1421 | SpearmanR: 0.5890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 187/187 [09:05<00:00,  2.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  94%|█████████▍| 47/50 [00:35<00:02,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0149 | Val Loss: 0.1308 | SpearmanR: 0.5705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 187/187 [00:02<00:00, 71.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  76%|███████▌  | 38/50 [00:29<00:09,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0150 | Val Loss: 0.1428 | SpearmanR: 0.5645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 187/187 [00:02<00:00, 71.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  80%|████████  | 40/50 [00:30<00:07,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0340 | Val Loss: 0.1568 | SpearmanR: 0.5799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 187/187 [00:02<00:00, 70.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:25<00:13,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0414 | Val Loss: 0.1299 | SpearmanR: 0.5718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 187/187 [00:02<00:00, 70.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 12/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 192 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  90%|█████████ | 45/50 [00:36<00:04,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0222 | Val Loss: 0.1329 | SpearmanR: 0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 192 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  90%|█████████ | 45/50 [00:35<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0127 | Val Loss: 0.1138 | SpearmanR: 0.6878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 11 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:26<00:13,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0351 | Val Loss: 0.1601 | SpearmanR: 0.5975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 186/186 [00:02<00:00, 71.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:39<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0236 | Val Loss: 0.1197 | SpearmanR: 0.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 186/186 [00:02<00:00, 71.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:36<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0148 | Val Loss: 0.1316 | SpearmanR: 0.6024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 186/186 [00:02<00:00, 71.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:38<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0335 | Val Loss: 0.1480 | SpearmanR: 0.6090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 186/186 [00:02<00:00, 71.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  90%|█████████ | 45/50 [00:36<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0277 | Val Loss: 0.1279 | SpearmanR: 0.6063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 186/186 [00:02<00:00, 71.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 13/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 208 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:38<00:03,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0150 | Val Loss: 0.1216 | SpearmanR: 0.6072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 208 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:40<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0131 | Val Loss: 0.1152 | SpearmanR: 0.6632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 12 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:30<00:10,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0350 | Val Loss: 0.1427 | SpearmanR: 0.6272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 185/185 [00:02<00:00, 71.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:25<00:17,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0322 | Val Loss: 0.1473 | SpearmanR: 0.5964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 185/185 [00:02<00:00, 71.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  84%|████████▍ | 42/50 [00:35<00:06,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0150 | Val Loss: 0.1336 | SpearmanR: 0.6008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 185/185 [00:02<00:00, 71.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:40<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0130 | Val Loss: 0.1440 | SpearmanR: 0.5768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 185/185 [00:02<00:00, 70.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:28<00:13,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0267 | Val Loss: 0.1432 | SpearmanR: 0.6019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 185/185 [00:02<00:00, 71.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 14/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 224 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  76%|███████▌  | 38/50 [00:32<00:10,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0275 | Val Loss: 0.1438 | SpearmanR: 0.6259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 70.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 224 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:42<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0161 | Val Loss: 0.1085 | SpearmanR: 0.6936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 70.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 13 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  58%|█████▊    | 29/50 [00:25<00:18,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0535 | Val Loss: 0.1315 | SpearmanR: 0.6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 184/184 [00:02<00:00, 71.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  64%|██████▍   | 32/50 [00:27<00:15,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0233 | Val Loss: 0.1372 | SpearmanR: 0.6205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 184/184 [00:02<00:00, 71.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:29<00:13,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0361 | Val Loss: 0.1444 | SpearmanR: 0.5978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 184/184 [00:02<00:00, 70.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  96%|█████████▌| 48/50 [00:41<00:01,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0370 | Val Loss: 0.1535 | SpearmanR: 0.6037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 184/184 [00:02<00:00, 71.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  92%|█████████▏| 46/50 [00:39<00:03,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0230 | Val Loss: 0.1301 | SpearmanR: 0.6176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 184/184 [00:02<00:00, 71.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 15/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 240 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:29<00:15,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0484 | Val Loss: 0.1425 | SpearmanR: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 71.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 240 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:44<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0234 | Val Loss: 0.1321 | SpearmanR: 0.7004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 70.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 14 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  68%|██████▊   | 34/50 [00:30<00:14,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0502 | Val Loss: 0.1171 | SpearmanR: 0.6457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 183/183 [00:02<00:00, 68.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:27<00:18,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0413 | Val Loss: 0.1298 | SpearmanR: 0.6586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 183/183 [00:02<00:00, 71.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  44%|████▍     | 22/50 [00:20<00:25,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0533 | Val Loss: 0.1228 | SpearmanR: 0.6539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 183/183 [00:02<00:00, 71.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  56%|█████▌    | 28/50 [00:25<00:20,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0486 | Val Loss: 0.1217 | SpearmanR: 0.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 183/183 [00:02<00:00, 71.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Model 5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  66%|██████▌   | 33/50 [00:30<00:15,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0326 | Val Loss: 0.1216 | SpearmanR: 0.6405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Surveying]: 100%|██████████| 183/183 [00:02<00:00, 70.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble training complete, submitting predictions for next cycle.\n",
      "\n",
      "Cycle 16/64\n",
      "-------------------------------------------------\n",
      "Selecting new data points...\n",
      "Training and evaluating model using 256 actively selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  74%|███████▍  | 37/50 [00:34<00:12,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0402 | Val Loss: 0.1274 | SpearmanR: 0.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 70.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating model using 256 randomly selected samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  60%|██████    | 30/50 [00:28<00:18,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping triggered after 10 epochs with no improvement.\n",
      "Train Loss: 0.0235 | Val Loss: 0.1274 | SpearmanR: 0.6650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 25/25 [00:00<00:00, 72.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress for experiment 15 appended to active_vs_standard_learning_curve_test.csv\n",
      "Starting ensemble training and pool evaluation...\n",
      "\n",
      "Training Model 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]:  82%|████████▏ | 41/50 [00:38<00:08,  1.08it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m PATIENCE = \u001b[32m10\u001b[39m\n\u001b[32m      6\u001b[39m N_MODELS = \u001b[32m5\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mget_learning_curves\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43minitial_n_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_samples_per_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mLEARNING_RATE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mWEIGHT_DECAY\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtraining_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPATIENCE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_models\u001b[49m\u001b[43m=\u001b[49m\u001b[43mN_MODELS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mactive_vs_standard_learning_curve_test.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mget_learning_curves\u001b[39m\u001b[34m(n_samples, initial_n_samples, n_samples_per_batch, model_name, learning_rate, weight_decay, epochs, training_pool, val_dataloader, test_dataloader, patience, n_models, results_path)\u001b[39m\n\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting ensemble training and pool evaluation...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     ensemble_predictions = \u001b[43mtrain_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     current_cycle += \u001b[32m1\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m all_results_df\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mtrain_ensemble\u001b[39m\u001b[34m(n_models, model_name, learning_rate, weight_decay, epochs, train_dataloader, pool_dataloader, val_dataloader, patience)\u001b[39m\n\u001b[32m     20\u001b[39m torch.cuda.manual_seed(i)\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# initialize and train a new model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m model = \u001b[43minitialize_and_train_new_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# get model predictions on pool dataloader, append to ensemble predictions list\u001b[39;00m\n\u001b[32m     26\u001b[39m pool_preds = get_model_predictions(model, pool_dataloader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36minitialize_and_train_new_model\u001b[39m\u001b[34m(model_name, learning_rate, weight_decay, epochs, train_dataloader, val_dataloader, patience, return_history, checkpoint_path)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# main training loop\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), desc=\u001b[33m\"\u001b[39m\u001b[33m[Training]\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     train_loss = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m     val_loss, spearmanr = val_step(model, val_dataloader, spearman)\n\u001b[32m     29\u001b[39m     train_loss_history.append(train_loss)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, optimizer, train_dataloader)\u001b[39m\n\u001b[32m     30\u001b[39m     loss.backward()\n\u001b[32m     31\u001b[39m     optimizer.step()\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     total_train_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m avg_train_loss = total_train_loss / \u001b[38;5;28mlen\u001b[39m(train_dataloader)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m avg_train_loss\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"facebook/esm2_t6_8M_UR50D\"\n",
    "LEARNING_RATE = 2e-5\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 50\n",
    "PATIENCE = 10\n",
    "N_MODELS = 5\n",
    "\n",
    "get_learning_curves(\n",
    "    n_samples=1024,\n",
    "    initial_n_samples=16,\n",
    "    n_samples_per_batch=16,\n",
    "    model_name=MODEL_NAME,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    epochs=EPOCHS,\n",
    "    training_pool=training_pool,\n",
    "    val_dataloader=val_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    patience=PATIENCE,\n",
    "    n_models=N_MODELS,\n",
    "    results_path='results/01_basic_ensemble/active_vs_standard_learning_curve_test.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e2ecc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>changing_var</th>\n",
       "      <th>local_exp_idx</th>\n",
       "      <th>value</th>\n",
       "      <th>training_method</th>\n",
       "      <th>avg_test_loss</th>\n",
       "      <th>spearmanr</th>\n",
       "      <th>pearsonr</th>\n",
       "      <th>final_mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n_samples</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>active</td>\n",
       "      <td>0.231729</td>\n",
       "      <td>0.346602</td>\n",
       "      <td>0.355572</td>\n",
       "      <td>0.231741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n_samples</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.241196</td>\n",
       "      <td>0.334375</td>\n",
       "      <td>0.333970</td>\n",
       "      <td>0.241775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n_samples</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>active</td>\n",
       "      <td>0.210936</td>\n",
       "      <td>0.363917</td>\n",
       "      <td>0.345005</td>\n",
       "      <td>0.211002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n_samples</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>standard</td>\n",
       "      <td>0.158877</td>\n",
       "      <td>0.515694</td>\n",
       "      <td>0.487750</td>\n",
       "      <td>0.159446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n_samples</td>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>active</td>\n",
       "      <td>0.190014</td>\n",
       "      <td>0.340015</td>\n",
       "      <td>0.291866</td>\n",
       "      <td>0.190051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  changing_var  local_exp_idx  value training_method  avg_test_loss  \\\n",
       "0    n_samples              0     16          active       0.231729   \n",
       "1    n_samples              0     16        standard       0.241196   \n",
       "2    n_samples              1     32          active       0.210936   \n",
       "3    n_samples              1     32        standard       0.158877   \n",
       "4    n_samples              2     48          active       0.190014   \n",
       "\n",
       "   spearmanr  pearsonr  final_mse  \n",
       "0   0.346602  0.355572   0.231741  \n",
       "1   0.334375  0.333970   0.241775  \n",
       "2   0.363917  0.345005   0.211002  \n",
       "3   0.515694  0.487750   0.159446  \n",
       "4   0.340015  0.291866   0.190051  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "lc_df = pd.read_csv(\"results/01_basic_ensemble/active_vs_standard_learning_curve_test.csv\")\n",
    "lc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4119833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "training_method=active<br>value=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "active",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "active",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "EAAgADAAQABQAGAAcACAAJAAoACwAMAA0ADgAPAAAAE=",
          "dtype": "i2"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAA4Lsu1j8AAACga0rXPwAAAADOwtU/////n71p3T8AAAAgR6ngPwAAAKAQNeE//////92O3T8AAABgA4/gPwAAAGA3O+A/AAAAYO3R4T8AAABAOj3jPwAAAIDJmeM/AAAAQL7K5D8AAADgkvDkPwAAAKBXKOU/AAAAYELL5D8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "training_method=standard<br>value=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "standard",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines",
         "name": "standard",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "EAAgADAAQABQAGAAcACAAJAAoACwAMAA0ADgAPAAAAE=",
          "dtype": "i2"
         },
         "xaxis": "x",
         "y": {
          "bdata": "AAAAgGRm1T8AAADAkYDgP////98Ltd4/AAAAYC3N4D8AAACAHJDePwAAACCMUuQ/AAAAAOXv4D8AAACgzSHjPwAAAMBkouY/AAAAoCi+5D8AAAAgqRblPwAAAAB7i+U/AAAAgEuJ5T8AAABgOQHmPwAAAEBe7uU/AAAAAPG35T8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "training_method"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Number of Training Samples"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Spearman Correlation Coefficient"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(lc_df, 'value', 'spearmanr',color=\"training_method\")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Number of Training Samples\",\n",
    "    yaxis_title=\"Spearman Correlation Coefficient\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fe63e9",
   "metadata": {},
   "source": [
    "### Discussion\n",
    "This active learning approach, at least with these set of parameters, actually seems to perform consistently worse than selecting samples randomly. This suggests that something about the acquisition function is not just ineffective, but biased toward less informative samples. If I had to guess, I would say that the model is indeed probably unsure about the samples, but the samples themselves may not be that different from each other. This would be an issue with any of the approaches, so I should look deeper into alternative methods for acquisition.\n",
    "\n",
    "Another thing to consider is the dataset size. The pool of samples I'm pulling from is quite small. It's difficult to say how this would perform if I had unlimited possibilities of next sample to test. Perhaps this scheme would perform differently in different datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba22eac",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plm-active-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
