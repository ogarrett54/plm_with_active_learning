{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55dfe726",
   "metadata": {},
   "source": [
    "# Diagnostic 1: Testing Read Count Relationship to Model Fine-tuning Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3dd56",
   "metadata": {},
   "source": [
    "I have tried several different active learning schemes, with none of them yielding an improvement in overall performance, and some of them yielding worse performance. This suggests that there's some kind of systematic bias being introduced during the active learning process. One hypothesis is that the active learning process trends towards uncommon sequences that have reduced read counts, and are therefore noisier measurements. To test this, I'll see if there's any relationship between model performance on limited data and the threshold of read counts used to filter the training pool from which the model draws from each time. If read counts alone are inducing this bias, then we would expect to see improved model performance as the threshold increases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b2131f",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae64c343",
   "metadata": {},
   "source": [
    "First, we have to modify the way we process the sequencing data to output a file that includes the read counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9655f024",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "def preprocess_data(df): # receives raw df from excel document provided by Genewiz Amplicon EZ, outputs df with receptor sequences and read counts.\n",
    "  # remove indels\n",
    "  df_no_indel = df[df['IndelLength'] == 0]\n",
    "  # remove truncated sequences\n",
    "  df_no_trunc = df_no_indel[df_no_indel['TargetAA'].str.len() == 99]\n",
    "  # remove adapters\n",
    "  df_no_adapters = df_no_trunc.copy()\n",
    "  df_no_adapters['TargetAA'] = df_no_adapters[\"TargetAA\"].str[19:-2]\n",
    "  # remove x-containing sequences\n",
    "  df_no_x = df_no_adapters[~df_no_adapters[\"TargetAA\"].str.contains('X')]\n",
    "  # create new dataframe with only unique AA and their summed reads\n",
    "  df_processed = df_no_x.groupby('TargetAA',)['Reads'].sum().reset_index()\n",
    "  df_processed = df_processed.sort_values('Reads',ascending = False).reset_index()\n",
    "  return df_processed\n",
    "\n",
    "def add_missing_sequences(lib_df, sel_df):\n",
    "  # add sequences present in selected group that weren't present in the library group to the library with read count 1\n",
    "  lib_df['source'] = 'library'\n",
    "  sel_df['source'] = 'selected'\n",
    "\n",
    "  combined_df = pd.concat([sel_df[['TargetAA', 'Reads', 'source']], lib_df[['TargetAA', 'Reads', 'source']]], ignore_index=True)\n",
    "\n",
    "  # Identify sequences unique to the selected dataset\n",
    "  unique_to_selected = combined_df.loc[combined_df['source'] == 'selected', 'TargetAA'].drop_duplicates()\n",
    "\n",
    "  # Check which of these unique sequences are not in the library\n",
    "  missing_in_library = ~unique_to_selected.isin(lib_df['TargetAA'])\n",
    "\n",
    "  # Create a DataFrame for these missing sequences with a count of 1\n",
    "  missing_sequences = pd.DataFrame({\n",
    "      'TargetAA': unique_to_selected[missing_in_library],\n",
    "      'Reads': 1,\n",
    "      'source': 'library'\n",
    "  })\n",
    "\n",
    "  # Add these missing sequences to the library DataFrame\n",
    "  lib_df_updated = pd.concat([lib_df, missing_sequences], ignore_index=True)\n",
    "  return lib_df_updated\n",
    "\n",
    "def remove_low_abundance_seq(df, threshold):\n",
    "  df_without_low_abundance = df[df['Reads'] >= threshold]\n",
    "  return df_without_low_abundance\n",
    "\n",
    "def process_and_calculate_enrichment(sel_df, lib_df, threshold):\n",
    "  # preprocess data\n",
    "  df_sel_processed = preprocess_data(sel_df)\n",
    "  df_lib_processed = preprocess_data(lib_df)\n",
    "  df_lib_processed = add_missing_sequences(df_lib_processed, df_sel_processed)\n",
    "  df_lib_processed = remove_low_abundance_seq(df_lib_processed, threshold)\n",
    "\n",
    "  # Calculate enrichment scores\n",
    "  pseudo_count = 1  # To avoid dividing by zero\n",
    "\n",
    "  df_sel_processed[\"proportion_selected\"] = (df_sel_processed['Reads'] + pseudo_count) / (df_sel_processed['Reads'].sum() + pseudo_count)\n",
    "  df_lib_processed['proportion_library'] = (df_lib_processed['Reads'] + pseudo_count) / (df_lib_processed['Reads'].sum() + pseudo_count)\n",
    "\n",
    "  # Merge dataframes on sequence\n",
    "  df_merged = pd.merge(df_sel_processed, df_lib_processed, on='TargetAA', suffixes=('_selected', '_library'))\n",
    "\n",
    "  # Calculate enrichment score\n",
    "  df_merged['enrichment_score'] = np.log10(df_merged['proportion_selected'] / df_merged['proportion_library'])\n",
    "\n",
    "  # Sort by enrichment\n",
    "  df_enrichment_sorted = df_merged.sort_values(by='enrichment_score', ascending=False)\n",
    "  df_enrichment_sorted = df_enrichment_sorted.rename(columns={'TargetAA': 'aa_sequence'})\n",
    "  df_enrichment_sorted = df_enrichment_sorted.rename(columns={'Reads_selected': 'sorted_reads'})\n",
    "  df_enrichment_sorted = df_enrichment_sorted.rename(columns={'Reads_library': 'library_reads'})\n",
    "  df_final = df_enrichment_sorted[['aa_sequence', 'enrichment_score', 'library_reads', 'sorted_reads']]\n",
    "  return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02193df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_lib = pd.read_excel(\"library1_raw.xlsx\")\n",
    "df_sel = pd.read_excel(\"sort1_C_raw.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13339132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save threshold 10 as the baseline\n",
    "df = process_and_calculate_enrichment(df_sel, df_lib, 10)\n",
    "df.to_csv(f\"avrpikC_full_with_read_counts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabccf76",
   "metadata": {},
   "source": [
    "## Preparing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a14e5c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57aac0dcb694924b6e281f49f4d0e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f27415784af46bf8d1a8dd0c66fcebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/93.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea86fbef168a4af0bd6a0b11770bf20d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# input threshold 10 data into torch Dataset, include library read counts as an attribute\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class BindingDataset(Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.sequences = df['aa_sequence']\n",
    "    self.scores = df['enrichment_score']\n",
    "    self.reads = df['library_reads']\n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(\"facebook/esm2_t6_8M_UR50D\")\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.sequences)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sequence = self.sequences[idx]\n",
    "    label = torch.tensor(self.scores[idx], dtype=torch.float)\n",
    "\n",
    "    # tokenize the sequence\n",
    "    tokenized = self.tokenizer(\n",
    "        sequence,\n",
    "        max_length=80, # 78 residues + 2 extra tokens\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # return input_ids: attention masks, removing the batch dimension\n",
    "    inputs = {key: val.squeeze(0) for key, val in tokenized.items()}\n",
    "\n",
    "    return inputs, label\n",
    "\n",
    "df = pd.read_csv(\"avrpikC_full_with_read_counts.csv\")\n",
    "full_dataset = BindingDataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5954076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train val test split on threshold 10 data\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "torch.manual_seed(42)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "val_split = 0.1\n",
    "test_split = 0.1\n",
    "\n",
    "# Calculate split sizes\n",
    "total_len = len(full_dataset)\n",
    "val_len = int(total_len * val_split)\n",
    "test_len = int(total_len * test_split)\n",
    "train_len = total_len - val_len - test_len\n",
    "\n",
    "# Split into training pool, validation, and test sets\n",
    "training_pool, val_dataset, test_dataset = random_split(full_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# Create fixed DataLoaders for validation and test sets\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "555f9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Subset\n",
    "\n",
    "# from training pool, get indices that have read counts above each threshold\n",
    "# Access the indices of the training_pool subset\n",
    "training_pool_original_indices = np.array(training_pool.indices)\n",
    "training_pool_reads = full_dataset.reads.iloc[training_pool_original_indices]\n",
    "\n",
    "thresholds = [10, 12, 15, 18, 21, 24]\n",
    "sample_sizes = [32, 64, 128, 256]\n",
    "\n",
    "datasets = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "  # Get the indices within the training_pool_original_indices where the read count meets the threshold\n",
    "  indices_within_training_pool = training_pool_original_indices[training_pool_reads >= threshold]\n",
    "\n",
    "  for sample_size in sample_sizes:\n",
    "    # Check if there are enough indices to sample from\n",
    "    if len(indices_within_training_pool) < sample_size:\n",
    "        print(f\"Warning: Not enough sequences ({len(indices_within_training_pool)}) above threshold {threshold} in training pool to sample {sample_size}. Skipping this combination.\")\n",
    "        continue # Skip to the next sample size\n",
    "\n",
    "    # Sample from the indices *within the training_pool_original_indices*\n",
    "    subset_indices = np.random.choice(indices_within_training_pool, sample_size, False)\n",
    "\n",
    "    # Create the Subset using indices relative to the original dataset\n",
    "    # The Subset class handles the mapping from these original indices to the subset's internal indices\n",
    "    subset = Subset(full_dataset, subset_indices)\n",
    "    dataset_dict = {\n",
    "        'reads': threshold,\n",
    "        'samples': sample_size,\n",
    "        'dataset': subset,\n",
    "        }\n",
    "    datasets.append(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d241d7",
   "metadata": {},
   "source": [
    "## Run experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f8086e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 10, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oscar/miniconda3/envs/plm-active-learning/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "[Training]: 100%|██████████| 50/50 [00:13<00:00,  3.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0656 | Val Loss: 0.1388 | SpearmanR: 0.3366\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 73.88it/s]\n",
      "/tmp/ipykernel_3452/3803460072.py:36: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, pd.DataFrame([results_dict])], ignore_index=True) # Append the results to the DataFrame\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 10, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:12<00:00,  3.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0373 | Val Loss: 0.1358 | SpearmanR: 0.5086\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 77.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 10, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:14<00:00,  3.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0606 | Val Loss: 0.1281 | SpearmanR: 0.4666\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 10, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0256 | Val Loss: 0.0792 | SpearmanR: 0.6990\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 72.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 12, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:10<00:00,  4.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0268 | Val Loss: 0.1255 | SpearmanR: 0.3985\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 73.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 12, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:12<00:00,  4.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0369 | Val Loss: 0.1445 | SpearmanR: 0.4687\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 12, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:15<00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0291 | Val Loss: 0.0915 | SpearmanR: 0.6626\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 73.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 12, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:21<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0125 | Val Loss: 0.0715 | SpearmanR: 0.7226\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 73.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 15, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:09<00:00,  5.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0766 | Val Loss: 0.1359 | SpearmanR: 0.4181\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 72.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 15, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:12<00:00,  3.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0259 | Val Loss: 0.1029 | SpearmanR: 0.5959\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 70.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 15, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:16<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0357 | Val Loss: 0.0977 | SpearmanR: 0.6244\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 15, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:21<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0180 | Val Loss: 0.0649 | SpearmanR: 0.7698\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 74.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 18, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:10<00:00,  4.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0937 | Val Loss: 0.1432 | SpearmanR: 0.4881\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 74.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 18, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:11<00:00,  4.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0252 | Val Loss: 0.1157 | SpearmanR: 0.5662\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 18, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:15<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0413 | Val Loss: 0.0916 | SpearmanR: 0.6558\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 18, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0198 | Val Loss: 0.0774 | SpearmanR: 0.7028\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 74.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 21, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:10<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0636 | Val Loss: 0.1213 | SpearmanR: 0.4771\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 73.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 21, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:12<00:00,  4.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0268 | Val Loss: 0.1290 | SpearmanR: 0.4374\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 21, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:15<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0233 | Val Loss: 0.1373 | SpearmanR: 0.5060\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 74.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 21, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:22<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0190 | Val Loss: 0.0702 | SpearmanR: 0.7175\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 24, and 32 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:11<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0510 | Val Loss: 0.1478 | SpearmanR: 0.3449\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 74.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 24, and 64 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:12<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0403 | Val Loss: 0.1138 | SpearmanR: 0.5604\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 24, and 128 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:16<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0393 | Val Loss: 0.1366 | SpearmanR: 0.6272\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 75.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with threshold 24, and 256 samples\n",
      "---------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Training]: 100%|██████████| 50/50 [00:23<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0277 | Val Loss: 0.0777 | SpearmanR: 0.7144\n",
      "\n",
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Testing]: 100%|██████████| 10/10 [00:00<00:00, 67.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>samples</th>\n",
       "      <th>spearmanr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0.366320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>64</td>\n",
       "      <td>0.541817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>0.543210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>0.742074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>0.448068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>64</td>\n",
       "      <td>0.441382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>128</td>\n",
       "      <td>0.694497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>256</td>\n",
       "      <td>0.727022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>32</td>\n",
       "      <td>0.485453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>64</td>\n",
       "      <td>0.646631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>128</td>\n",
       "      <td>0.616988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>256</td>\n",
       "      <td>0.750098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>0.446371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>64</td>\n",
       "      <td>0.602223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18</td>\n",
       "      <td>128</td>\n",
       "      <td>0.661569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>256</td>\n",
       "      <td>0.676435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0.518151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>21</td>\n",
       "      <td>64</td>\n",
       "      <td>0.492146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>21</td>\n",
       "      <td>128</td>\n",
       "      <td>0.510020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>21</td>\n",
       "      <td>256</td>\n",
       "      <td>0.699729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>32</td>\n",
       "      <td>0.288961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>24</td>\n",
       "      <td>64</td>\n",
       "      <td>0.485631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>24</td>\n",
       "      <td>128</td>\n",
       "      <td>0.609542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>256</td>\n",
       "      <td>0.671724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold samples  spearmanr\n",
       "0         10      32   0.366320\n",
       "1         10      64   0.541817\n",
       "2         10     128   0.543210\n",
       "3         10     256   0.742074\n",
       "4         12      32   0.448068\n",
       "5         12      64   0.441382\n",
       "6         12     128   0.694497\n",
       "7         12     256   0.727022\n",
       "8         15      32   0.485453\n",
       "9         15      64   0.646631\n",
       "10        15     128   0.616988\n",
       "11        15     256   0.750098\n",
       "12        18      32   0.446371\n",
       "13        18      64   0.602223\n",
       "14        18     128   0.661569\n",
       "15        18     256   0.676435\n",
       "16        21      32   0.518151\n",
       "17        21      64   0.492146\n",
       "18        21     128   0.510020\n",
       "19        21     256   0.699729\n",
       "20        24      32   0.288961\n",
       "21        24      64   0.485631\n",
       "22        24     128   0.609542\n",
       "23        24     256   0.671724"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.training import initialize_and_train_new_model, test_model\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize dataframe to store results\n",
    "results = pd.DataFrame(columns=['threshold', 'samples', 'spearmanr'])\n",
    "\n",
    "# for each subset\n",
    "for dataset in datasets:\n",
    "  # create a new DataLoader\n",
    "  train_dataloader = DataLoader(dataset['dataset'], batch_size=32, shuffle=True)\n",
    "\n",
    "  # train model for 20 epochs\n",
    "  print(f'\\nTraining with threshold {dataset[\"reads\"]}, and {dataset[\"samples\"]} samples')\n",
    "  print('---------------------------------------------------------------------------------')\n",
    "  model = initialize_and_train_new_model(\n",
    "      'cls-based',\n",
    "      'facebook/esm2_t6_8M_UR50D',\n",
    "      2e-5,\n",
    "      0.01,\n",
    "      50, # Reduced epochs for demonstration, you can change this back to 20\n",
    "      train_dataloader,\n",
    "      val_dataloader,\n",
    "      patience=50,\n",
    "  )\n",
    "  # test model\n",
    "  print(f'\\nTesting')\n",
    "  test_results = test_model(model, test_dataloader, True) # Store the result in a temporary variable\n",
    "\n",
    "  # append results\n",
    "  results_dict = {\n",
    "      'threshold': dataset['reads'],\n",
    "      'samples': dataset['samples'],\n",
    "      'spearmanr': test_results['spearmanr'] # Access 'spearmanr' from the test_results dictionary\n",
    "  }\n",
    "  results = pd.concat([results, pd.DataFrame([results_dict])], ignore_index=True) # Append the results to the DataFrame\n",
    "  results.to_csv(\"results/05_impact_of_read_counts/learning_curve.csv\", index=False)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e17897",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2852ce8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "threshold=10<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "10",
         "line": {
          "color": "#636efa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "10",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAYMlx1z8AAACgj1bhPwAAAKD6YeE/AAAAIBK/5z8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "threshold=12<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "12",
         "line": {
          "color": "#EF553B",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "12",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAwCOt3D8AAAAgmj/cPwAAAMBROeY/AAAAQMND5z8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "threshold=15<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "15",
         "line": {
          "color": "#00cc96",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "15",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoKcR3z8AAAAANLHkPwAAAGBdvuM/AAAAgM4A6D8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "threshold=18<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "18",
         "line": {
          "color": "#ab63fa",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "18",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAoFWR3D8AAABgaEXjPwAAAICTK+U/AAAAIFul5T8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "threshold=21<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "21",
         "line": {
          "color": "#FFA15A",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "21",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAALKU4D8AAABAUn/fPwAAAGAVUuA/AAAA4C1k5j8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        },
        {
         "hovertemplate": "threshold=24<br>samples=%{x}<br>spearmanr=%{y}<extra></extra>",
         "legendgroup": "24",
         "line": {
          "color": "#19d3f3",
          "dash": "solid"
         },
         "marker": {
          "symbol": "circle"
         },
         "mode": "lines+markers",
         "name": "24",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": [
          32,
          64,
          128,
          256
         ],
         "xaxis": "x",
         "y": {
          "bdata": "AAAAgFd+0j8AAAAAlRTfPwAAAGBegeM/AAAAoMJ+5T8=",
          "dtype": "f8"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "Threshold"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Spearman Correlation vs. Sample Size by Threshold"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Sample Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Spearman Correlation"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves with plotly\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "fig = px.line(results,\n",
    "              x=\"samples\",\n",
    "              y=\"spearmanr\",\n",
    "              color=\"threshold\",\n",
    "              title=\"Spearman Correlation vs. Sample Size by Threshold\",\n",
    "              markers=True) # Add markers to show data points\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Sample Size\",\n",
    "    yaxis_title=\"Spearman Correlation\",\n",
    "    legend_title=\"Threshold\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a941df3",
   "metadata": {},
   "source": [
    "This is now the second time I've run this experiment and analysis, and with this second replicate, it seems pretty clear that there isn't going to be any statistically discernable differences between thresholds. This means read count bias is unlikely to be the culprit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0a04ef",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plm-active-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
